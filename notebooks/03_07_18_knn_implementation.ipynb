{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import diff_classifier.aws as aws\n",
    "import boto3\n",
    "import skimage.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '01_18_Experiment'\n",
    "\n",
    "missing = []\n",
    "for i in range(10, 15):\n",
    "    missing.append(\"P1_S2_R_00{}\".format(i))\n",
    "\n",
    "for i in range(10, 15):\n",
    "    missing.append(\"P2_S3_L_00{}\".format(i))\n",
    "    \n",
    "for i in range(0, 15):\n",
    "    missing.append(\"P3_S3_L_{}\".format(\"%04d\" % i))\n",
    "\n",
    "pups = [\"P3\", \"P2\", \"P1\"]\n",
    "slices = [\"S1\", \"S2\", \"S3\"]\n",
    "folder = '01_18_Experiment'\n",
    "\n",
    "hemis = [\"R\", \"L\"]\n",
    "vids = 15\n",
    "\n",
    "tnum=20 #number of training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = []\n",
    "\n",
    "for pup in pups:\n",
    "    for hemi in hemis:\n",
    "            for slic in slices:\n",
    "                for vid in range(0, vids):\n",
    "                            prefix = \"{}_{}_{}_{}\".format(pup, slic, hemi, \"%04d\" % vid)\n",
    "                            if not prefix in missing:\n",
    "                                for row in range(0, 4):\n",
    "                                    for col in range(0, 4):\n",
    "                                        to_track.append(\"{}_{}_{}\".format(prefix, row, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprefix = []\n",
    "for i in range(0, tnum):\n",
    "    random.seed(i+1)\n",
    "    tprefix.append(to_track[random.randint(0, len(to_track))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1.5, 833.6, 9.24, 4.5, 3.3, 3.4, 2.85, 2.75, 3.7, 2.45,\n",
    "              2.6, 3.1, 3.25, 2.85, 2.05, 2.9, 5.4, 5.0, 2.7, 530])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in tprefix:\n",
    "#    remote_folder = \"01_18_Experiment/{}\".format(name.split('_')[0])\n",
    "#    aws.download_s3(remote_folder+'/'+name+'.tif', name+'.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = np.zeros((tnum, 4))\n",
    "counter = 0\n",
    "for name in tprefix:\n",
    "    local_im = name + '.tif'\n",
    "    test_image = sio.imread(local_im)\n",
    "    descriptors[counter, 0] = np.mean(test_image[0, :, :])\n",
    "    descriptors[counter, 1] = np.std(test_image[0, :, :])\n",
    "    descriptors[counter, 2] = np.percentile(test_image[0, :, :], 10)\n",
    "    descriptors[counter, 3] = np.percentile(test_image[0:, :, :], 90)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = descriptors\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(),\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pto_track = to_track[1:5]\n",
    "pX = np.zeros((len(pto_track), 4))\n",
    "counter = 0\n",
    "for name in pto_track:\n",
    "    #remote_folder = \"01_18_Experiment/{}\".format(name.split('_')[0])\n",
    "    #aws.download_s3(remote_folder+'/'+name+'.tif', name+'.tif')\n",
    "    \n",
    "    local_im = name + '.tif'\n",
    "    test_image = sio.imread(local_im)\n",
    "    pX[counter, 0] = np.mean(test_image[0, :, :])\n",
    "    pX[counter, 1] = np.std(test_image[0, :, :])\n",
    "    pX[counter, 2] = np.percentile(test_image[0, :, :], 10)\n",
    "    pX[counter, 3] = np.percentile(test_image[0:, :, :], 90)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "[3.395 3.395 3.395 3.395] \n",
      "\n",
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
      "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
      "       warm_start=False)\n",
      "[2.87887070e+16 2.90087105e+16 2.86525504e+16 2.90482189e+16] \n",
      "\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False)\n",
      "[3.19153224 2.90032939 1.92331934 2.86535238] \n",
      "\n",
      "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
      "     positive=False, precompute='auto', verbose=False)\n",
      "[6.03711963 5.80410499 4.94394373 5.76688076] \n",
      "\n",
      "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, threshold_lambda=10000.0, tol=0.001, verbose=False)\n",
      "[2.99609378 2.69169882 1.61856377 2.64479192] \n",
      "\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, random_state=None, shuffle=True,\n",
      "              tol=None, verbose=0, warm_start=False)\n",
      "[2.1739149  2.03856728 1.48928997 2.0161842 ] \n",
      "\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\enuser\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\enuser\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.91836655 3.61696407 2.80245441 3.63388712] \n",
      "\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "[2.86150446 2.33333375 1.51807543 2.5292831 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X, y)\n",
    "    print(clf.predict(pX), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P3_S1_R_0000_0_1',\n",
       " 'P3_S1_R_0000_0_2',\n",
       " 'P3_S1_R_0000_0_3',\n",
       " 'P3_S1_R_0000_1_0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pto_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
