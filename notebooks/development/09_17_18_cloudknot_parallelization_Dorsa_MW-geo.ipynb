{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define the terms of my experiment, among them the location of the files in S3 (bucket and folder name), and each of the video prefixes (everything before the file extension) that I want to track. \n",
    "\n",
    "Note that these videos should be similar-ish: while we can account for differences in mean intensities between videos, particle sizes should be approximately the same, and (slightly less important) particles should be moving at about the same order of magnitude speed. In this experiment, these videos were taken in 0.4% agarose gel at 100x magnification and 100.02 fps shutter speeds with nanoparticles of about 100nm in diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = []\n",
    "result_futures = {}\n",
    "start_knot = 25 #Must be unique number for every run on Cloudknot.\n",
    "\n",
    "remote_folder = 'Gel_studies' #Folder in AWS S3 containing files to be analyzed\n",
    "bucket = 'dtoghani.data'\n",
    "vids = 10\n",
    "mws = ['10k_PEG', '5k_PEG', '1k_PEG', '5k_PEG_NH2', 'PS_NH2', 'PS_COOH']\n",
    "calcs = [2, 3]\n",
    "for calc in calcs:\n",
    "    for mw in mws:\n",
    "        for num in range(1, vids+1):\n",
    "            #to_track.append('100x_0_4_1_2_gel_{}_bulk_vid_{}'.format(vis, num))\n",
    "            to_track.append('{}_{}mM_XY{}'.format(mw, calc, '%02d' % num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10k_PEG_2mM_XY01',\n",
       " '10k_PEG_2mM_XY02',\n",
       " '10k_PEG_2mM_XY03',\n",
       " '10k_PEG_2mM_XY04',\n",
       " '10k_PEG_2mM_XY05',\n",
       " '10k_PEG_2mM_XY06',\n",
       " '10k_PEG_2mM_XY07',\n",
       " '10k_PEG_2mM_XY08',\n",
       " '10k_PEG_2mM_XY09',\n",
       " '10k_PEG_2mM_XY10',\n",
       " '5k_PEG_2mM_XY01',\n",
       " '5k_PEG_2mM_XY02',\n",
       " '5k_PEG_2mM_XY03',\n",
       " '5k_PEG_2mM_XY04',\n",
       " '5k_PEG_2mM_XY05',\n",
       " '5k_PEG_2mM_XY06',\n",
       " '5k_PEG_2mM_XY07',\n",
       " '5k_PEG_2mM_XY08',\n",
       " '5k_PEG_2mM_XY09',\n",
       " '5k_PEG_2mM_XY10',\n",
       " '1k_PEG_2mM_XY01',\n",
       " '1k_PEG_2mM_XY02',\n",
       " '1k_PEG_2mM_XY03',\n",
       " '1k_PEG_2mM_XY04',\n",
       " '1k_PEG_2mM_XY05',\n",
       " '1k_PEG_2mM_XY06',\n",
       " '1k_PEG_2mM_XY07',\n",
       " '1k_PEG_2mM_XY08',\n",
       " '1k_PEG_2mM_XY09',\n",
       " '1k_PEG_2mM_XY10',\n",
       " '5k_PEG_NH2_2mM_XY01',\n",
       " '5k_PEG_NH2_2mM_XY02',\n",
       " '5k_PEG_NH2_2mM_XY03',\n",
       " '5k_PEG_NH2_2mM_XY04',\n",
       " '5k_PEG_NH2_2mM_XY05',\n",
       " '5k_PEG_NH2_2mM_XY06',\n",
       " '5k_PEG_NH2_2mM_XY07',\n",
       " '5k_PEG_NH2_2mM_XY08',\n",
       " '5k_PEG_NH2_2mM_XY09',\n",
       " '5k_PEG_NH2_2mM_XY10',\n",
       " 'PS_NH2_2mM_XY01',\n",
       " 'PS_NH2_2mM_XY02',\n",
       " 'PS_NH2_2mM_XY03',\n",
       " 'PS_NH2_2mM_XY04',\n",
       " 'PS_NH2_2mM_XY05',\n",
       " 'PS_NH2_2mM_XY06',\n",
       " 'PS_NH2_2mM_XY07',\n",
       " 'PS_NH2_2mM_XY08',\n",
       " 'PS_NH2_2mM_XY09',\n",
       " 'PS_NH2_2mM_XY10',\n",
       " 'PS_COOH_2mM_XY01',\n",
       " 'PS_COOH_2mM_XY02',\n",
       " 'PS_COOH_2mM_XY03',\n",
       " 'PS_COOH_2mM_XY04',\n",
       " 'PS_COOH_2mM_XY05',\n",
       " 'PS_COOH_2mM_XY06',\n",
       " 'PS_COOH_2mM_XY07',\n",
       " 'PS_COOH_2mM_XY08',\n",
       " 'PS_COOH_2mM_XY09',\n",
       " 'PS_COOH_2mM_XY10',\n",
       " '10k_PEG_3mM_XY01',\n",
       " '10k_PEG_3mM_XY02',\n",
       " '10k_PEG_3mM_XY03',\n",
       " '10k_PEG_3mM_XY04',\n",
       " '10k_PEG_3mM_XY05',\n",
       " '10k_PEG_3mM_XY06',\n",
       " '10k_PEG_3mM_XY07',\n",
       " '10k_PEG_3mM_XY08',\n",
       " '10k_PEG_3mM_XY09',\n",
       " '10k_PEG_3mM_XY10',\n",
       " '5k_PEG_3mM_XY01',\n",
       " '5k_PEG_3mM_XY02',\n",
       " '5k_PEG_3mM_XY03',\n",
       " '5k_PEG_3mM_XY04',\n",
       " '5k_PEG_3mM_XY05',\n",
       " '5k_PEG_3mM_XY06',\n",
       " '5k_PEG_3mM_XY07',\n",
       " '5k_PEG_3mM_XY08',\n",
       " '5k_PEG_3mM_XY09',\n",
       " '5k_PEG_3mM_XY10',\n",
       " '1k_PEG_3mM_XY01',\n",
       " '1k_PEG_3mM_XY02',\n",
       " '1k_PEG_3mM_XY03',\n",
       " '1k_PEG_3mM_XY04',\n",
       " '1k_PEG_3mM_XY05',\n",
       " '1k_PEG_3mM_XY06',\n",
       " '1k_PEG_3mM_XY07',\n",
       " '1k_PEG_3mM_XY08',\n",
       " '1k_PEG_3mM_XY09',\n",
       " '1k_PEG_3mM_XY10',\n",
       " '5k_PEG_NH2_3mM_XY01',\n",
       " '5k_PEG_NH2_3mM_XY02',\n",
       " '5k_PEG_NH2_3mM_XY03',\n",
       " '5k_PEG_NH2_3mM_XY04',\n",
       " '5k_PEG_NH2_3mM_XY05',\n",
       " '5k_PEG_NH2_3mM_XY06',\n",
       " '5k_PEG_NH2_3mM_XY07',\n",
       " '5k_PEG_NH2_3mM_XY08',\n",
       " '5k_PEG_NH2_3mM_XY09',\n",
       " '5k_PEG_NH2_3mM_XY10',\n",
       " 'PS_NH2_3mM_XY01',\n",
       " 'PS_NH2_3mM_XY02',\n",
       " 'PS_NH2_3mM_XY03',\n",
       " 'PS_NH2_3mM_XY04',\n",
       " 'PS_NH2_3mM_XY05',\n",
       " 'PS_NH2_3mM_XY06',\n",
       " 'PS_NH2_3mM_XY07',\n",
       " 'PS_NH2_3mM_XY08',\n",
       " 'PS_NH2_3mM_XY09',\n",
       " 'PS_NH2_3mM_XY10',\n",
       " 'PS_COOH_3mM_XY01',\n",
       " 'PS_COOH_3mM_XY02',\n",
       " 'PS_COOH_3mM_XY03',\n",
       " 'PS_COOH_3mM_XY04',\n",
       " 'PS_COOH_3mM_XY05',\n",
       " 'PS_COOH_3mM_XY06',\n",
       " 'PS_COOH_3mM_XY07',\n",
       " 'PS_COOH_3mM_XY08',\n",
       " 'PS_COOH_3mM_XY09',\n",
       " 'PS_COOH_3mM_XY10']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The videos used with this analysis are fairly large (2048 x 2048 pixels and 651 frames), and in cases like this, the tracking algorithm can quickly eat up RAM. In this case, we chose to crop the videos to 512 x 512 images such that we can run our jobs on smaller EC2 instances with 16GB of RAM. \n",
    "\n",
    "Note that larger jobs can be made with user-defined functions such that splitting isn't necessary-- or perhaps an intermediate amount of memory that contains splitting, tracking, and msd calculation functions all performed on a single EC2 instance.\n",
    "\n",
    "The compiled functions in the knotlets module require access to buckets on AWS. In this case, we will be using a publicly (read-only) bucket. If users want to run this notebook on their own, will have to transfer files from nancelab.publicfiles to their own bucket, as it requires writing to S3 buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.knotlets as kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track:\n",
    "    kn.split(prefix, remote_folder=remote_folder, bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking normally requires user input in the form of tracking parameters e.g. particle radius, linking max distance, max frame gap etc. When large datasets aren't required, each video can be manageably manually tracked using the TrackMate GUI. However, when datasets get large e.g. >20 videos, this can become extremely arduous. For videos that are fairly similar, you can get away with using similar tracking parameters across all videos. However, one parameter that is a little more noisy that the others is the quality filter value. Quality is a numerical value that approximate how likely a particle is to be \"real.\" \n",
    "\n",
    "In this case, I built a predictor that estimates the quality filter value based on intensity distributions from the input images. Using a relatively small training dataset (5-20 videos), users can get fairly good estimates of quality filter values that can be used in parallelized tracking workflows.\n",
    "\n",
    "Note: in the current setup, the predictor should be run in Python 3. While the code will run in Python 3, there are differences between the random number generators in Python2 and Python3 that I was not able to control for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import diff_classifier.imagej as ij\n",
    "import boto3\n",
    "import os.path as op\n",
    "import diff_classifier.aws as aws\n",
    "import diff_classifier.knotlets as kn\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regress_sys function should be run twice. When have_output is set to False, it generates a list of files that the user should manually track using Trackmate. Once the quality filter values are found, they can be used as input (y) to generate a regress object that can predict quality filter values for additional videos. Once y is assigned, set have_output to True and re-run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum=15 #number of training datasets\n",
    "pref = []\n",
    "for num in to_track:                    \n",
    "    for row in range(0, 4):\n",
    "        for col in range(0, 4):\n",
    "            pref.append(\"{}_{}_{}\".format(num, row, col))\n",
    "\n",
    "y = np.array([24.5, 3.0, 25.5, 24.4, 29.9, 8.5, 24.3, 20.7, 9.0,\n",
    "              20.6, 19.5, 20.6, 25.5, 42.2, 27.2])\n",
    "\n",
    "# Creates regression object based of training dataset composed of input images and manually\n",
    "# calculated quality cutoffs from tracking with GUI interface.\n",
    "regress = ij.regress_sys(remote_folder, pref, y, tnum, randselect=True,\n",
    "                         have_output=True, bucket_name=bucket)\n",
    "#Read up on how regress_sys works before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle object\n",
    "filename = 'regress.obj'\n",
    "with open(filename,'wb') as fp:\n",
    "    joblib.dump(regress,fp)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "aws.upload_s3(filename, remote_folder+'/'+filename, bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users should input all tracking parameters into the tparams object. Note that the quality value will be overwritten by values found using the quality predictor found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tparams1 = {'radius': 3.5, 'threshold': 0.0, 'do_median_filtering': False,\n",
    "           'quality': 10.0, 'xdims': (0, 511), 'ydims': (1, 511),\n",
    "           'median_intensity': 300.0, 'snr': 0.0, 'linking_max_distance': 12.0,\n",
    "           'gap_closing_max_distance': 13.0, 'max_frame_gap': 6,\n",
    "           'track_duration': 20.0}\n",
    "\n",
    "# tparams2 = {'radius': 4.0, 'threshold': 0.0, 'do_median_filtering': False,\n",
    "#            'quality': 10.0, 'xdims': (0, 511), 'ydims': (1, 511),\n",
    "#            'median_intensity': 300.0, 'snr': 0.0, 'linking_max_distance': 8.0,\n",
    "#            'gap_closing_max_distance': 12.0, 'max_frame_gap': 6,\n",
    "#            'track_duration': 20.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudknot setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloudknot requires the user to define a function that will be sent to multiple computers to run. In this case, the function knotlets.tracking will be used. We create a docker image that has the required installations (defined by the requirements.txt file from diff_classifier on Github, and the base Docker Image below that has Fiji pre-installed in the correct location.\n",
    "\n",
    "Note that I modify the Docker image below such that the correct version of boto3 is installed. For some reason, versions later than 1.5.28 error out, so I specified 5.28 as the correct version. Run my_image.build below to double-check that the Docker image is successfully built prior to submitting the job to Cloudknot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck\n",
    "import os.path as op\n",
    "import diff_classifier.msd as msd\n",
    "\n",
    "github_installs=('https://github.com/ccurtis7/diff_classifier.git@Chad')\n",
    "#my_image = ck.DockerImage(func=kn.tracking, base_image='arokem/python3-fiji:0.3', github_installs=github_installs)\n",
    "my_image = ck.DockerImage(func=kn.geomean_msd, base_image='arokem/python3-fiji:0.3', github_installs=github_installs)\n",
    "docker_file = open(my_image.docker_path)\n",
    "docker_string = docker_file.read()\n",
    "docker_file.close()\n",
    "\n",
    "req = open(op.join(op.split(my_image.docker_path)[0], 'requirements.txt'))\n",
    "req_string = req.read()\n",
    "req.close()\n",
    "\n",
    "new_req = req_string[0:req_string.find('\\n')-3]+'5.28'+ req_string[req_string.find('\\n'):]\n",
    "req_overwrite = open(op.join(op.split(my_image.docker_path)[0], 'requirements.txt'), 'w')\n",
    "req_overwrite.write(new_req)\n",
    "req_overwrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image.build(\"0.1\", image_name=\"test_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object all_maps is an iterable containing all the inputs sent to Cloudknot. This is useful, because if the user needs to modify some of the tracking parameters for a single video, this can be done prior to submission to Cloudknot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "all_maps = []\n",
    "for prefix in to_track:\n",
    "    all_maps.append((prefix, 0.07, 100.02, True, remote_folder, bucket, 651))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10k_PEG_2mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_2mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_2mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_2mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_NH2_2mM_XY01',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY02',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY03',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY04',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY05',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY06',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY07',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY08',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY09',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_2mM_XY10',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('PS_NH2_2mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_2mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_2mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('10k_PEG_3mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_3mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('1k_PEG_3mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('5k_PEG_NH2_3mM_XY01',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY02',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY03',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY04',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY05',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY06',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY07',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY08',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY09',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('5k_PEG_NH2_3mM_XY10',\n",
       "  0.07,\n",
       "  100.02,\n",
       "  True,\n",
       "  'Gel_studies',\n",
       "  'dtoghani.data',\n",
       "  651),\n",
       " ('PS_NH2_3mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_NH2_3mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY01', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY02', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY03', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY04', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY05', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY06', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY07', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY08', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY09', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651),\n",
       " ('PS_COOH_3mM_XY10', 0.07, 100.02, True, 'Gel_studies', 'dtoghani.data', 651)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cloudknot knot object sets up the compute environment which will run the code. Note that the name must be unique. Every time you submit a new knot, you should change the name. I do this with the variable start_knot, which I vary for each run.\n",
    "\n",
    "If larger jobs are anticipated, users can adjust both RAM and storage with the memory and image_id variables. Memory specifies the amount of RAM to be used. Users can build a customized AMI with as much space as they need, and enter the ID into image_ID. Read the Cloudknot documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot = ck.Knot(name='download_and_track_{}_b{}'.format('chad14', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 144000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-015a1b4cd3895860b', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',),\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot.clobber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures = knot.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures14 = knot13.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures15 = knot13.map(all_maps[0:2], starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures2 = knot.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot9.clobber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.aws.get_region()\n",
    "ck.aws.set_region('us-east-1')\n",
    "ck.aws.get_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot2 = ck.Knot(name='download_and_track_{}_b{}'.format('chad2', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 144000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures2 = knot2.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot3 = ck.Knot(name='download_and_track_{}_b{}'.format('chad3', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 144000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures3 = knot3.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot4 = ck.Knot(name='download_and_track_{}_b{}'.format('chad4', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 144000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures4 = knot4.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot5 = ck.Knot(name='download_and_track_{}_b{}'.format('chad5', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 144000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures5 = knot5.map(all_maps, starmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.aws.set_region('eu-west-1')\n",
    "knot5.clobber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tparams2 = {'radius': 3.5, 'threshold': 0.0, 'do_median_filtering': False,\n",
    "           'quality': 10.0, 'xdims': (0, 511), 'ydims': (1, 511),\n",
    "           'median_intensity': 300.0, 'snr': 0.0, 'linking_max_distance': 15.0,\n",
    "           'gap_closing_max_distance': 22.0, 'max_frame_gap': 5,\n",
    "           'track_duration': 20.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "all_maps2 = []\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    try:\n",
    "        s3.Object(bucket, '{}/Traj_{}.csv'.format(remote_folder, name)).load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            missing.append(name)\n",
    "            all_maps2.append((name, remote_folder, bucket, 'regress100.obj',\n",
    "                             4, 4, (512, 512), tparams2))\n",
    "        else:\n",
    "            print('Something else has gone wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.aws as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_folder = 'Gel_Studies/08_14_18_gel_validation/old_msds2'\n",
    "\n",
    "for name in missing:\n",
    "    filename = 'Traj_{}.csv'.format(name)\n",
    "    aws.download_s3('{}/{}'.format(old_folder, filename), filename, bucket_name=bucket)\n",
    "    aws.upload_s3(filename, '{}/{}'.format(remote_folder, filename), bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can monitor the progress of their job in the Batch interface. Once the code is complete, users should clobber their knot to make sure that all AWS resources are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot.clobber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knotlet.assemble_msds function (which can also potentially be submitted to Cloudknot as well for large jobs) calculates the mean squared displacements and trajectory features from the raw trajectory csv files found from the Cloudknot submission. It accesses them from the S3 bucket to which they were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track:\n",
    "    kn.assemble_msds(prefix, remote_folder, bucket=bucket)\n",
    "    print('Successfully output msds for {}'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in to_track[5:7]:\n",
    "    kn.assemble_msds(prefix, remote_folder, bucket='ccurtis.data')\n",
    "    print('Successfully output msds for {}'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps2 = []\n",
    "for prefix in to_track:    \n",
    "    all_maps2.append((prefix, remote_folder, bucket, 'regress100.obj',\n",
    "                     4, 4, (512, 512), tparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot = ck.Knot(name='download_and_track_{}_b{}'.format('chad', start_knot),\n",
    "               docker_image = my_image,\n",
    "               memory = 16000,\n",
    "               resource_type = \"SPOT\",\n",
    "               bid_percentage = 100,\n",
    "               #image_id = 'ami-0e00afdf500081a0d', #May need to change this line\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff_classifier includes some useful imaging tools as well, including checking trajectories, plotting heatmaps of trajectory features, distributions of diffusion coefficients, and MSD plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.heatmaps as hm\n",
    "import diff_classifier.aws as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = to_track[1]\n",
    "\n",
    "msds = 'msd_{}.csv'.format(prefix)\n",
    "feat = 'features_{}.csv'.format(prefix)\n",
    "aws.download_s3('{}/{}'.format(remote_folder, msds), msds, bucket_name=bucket)\n",
    "aws.download_s3('{}/{}'.format(remote_folder, feat), feat, bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_trajectories(prefix, upload=False, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomean, geoSEM = hm.plot_individual_msds(prefix, x_range=10, y_range=300, umppx=1, fps=1, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_heatmap(prefix, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_particles_in_frame(prefix, y_range=6000, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "all_maps2 = []\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    try:\n",
    "        s3.Object(bucket, '{}/Traj_{}.csv'.format(remote_folder, name)).load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            missing.append(name)\n",
    "            #all_maps2.append((name, remote_folder, bucket, 'regress.obj',\n",
    "            #                 4, 4, (512, 512), tparams2))\n",
    "        else:\n",
    "            print('Something else has gone wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = ['PS_COOH_2mM_XY05_1_1', 'PS_NH2_2mM_XY04_2_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.tracking(missing[0], remote_folder, bucket=bucket, tparams=tparams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.tracking(missing[1], remote_folder, bucket=bucket, tparams=tparams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
