{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import diff_classifier.aws as aws\n",
    "import diff_classifier.pca as pca\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_COOH_XY01.csv\n",
      "features_COOH_XY01.csv size: (14913, 67)\n",
      "features_COOH_XY02.csv\n",
      "features_COOH_XY02.csv size: (14225, 67)\n",
      "features_COOH_XY03.csv\n",
      "features_COOH_XY03.csv size: (14767, 67)\n",
      "features_COOH_XY04.csv\n",
      "features_COOH_XY04.csv size: (14936, 67)\n",
      "features_COOH_XY05.csv\n",
      "features_COOH_XY05.csv size: (15344, 67)\n",
      "features_COOH_XY06.csv\n",
      "features_COOH_XY06.csv size: (63173, 67)\n",
      "features_COOH_XY07.csv\n",
      "features_COOH_XY07.csv size: (42620, 67)\n",
      "features_COOH_XY08.csv\n",
      "features_COOH_XY08.csv size: (43427, 67)\n",
      "features_COOH_XY09.csv\n",
      "features_COOH_XY09.csv size: (19220, 67)\n",
      "features_COOH_XY10.csv\n",
      "features_COOH_XY10.csv size: (27610, 67)\n",
      "features_COOH_serum_XY01.csv\n",
      "features_COOH_serum_XY01.csv size: (42821, 67)\n",
      "features_COOH_serum_XY02.csv\n",
      "features_COOH_serum_XY02.csv size: (42778, 67)\n",
      "features_COOH_serum_XY03.csv\n",
      "features_COOH_serum_XY03.csv size: (42996, 67)\n",
      "features_COOH_serum_XY04.csv\n",
      "features_COOH_serum_XY04.csv size: (43391, 67)\n",
      "features_COOH_serum_XY05.csv\n",
      "features_COOH_serum_XY05.csv size: (43584, 67)\n",
      "features_COOH_serum_XY06.csv\n",
      "features_COOH_serum_XY06.csv size: (41418, 67)\n",
      "features_COOH_serum_XY07.csv\n",
      "features_COOH_serum_XY07.csv size: (42307, 67)\n",
      "features_COOH_serum_XY08.csv\n",
      "features_COOH_serum_XY08.csv size: (0, 67)\n",
      "features_COOH_serum_XY09.csv\n",
      "features_COOH_serum_XY09.csv size: (41761, 67)\n",
      "features_COOH_serum_XY10.csv\n",
      "features_COOH_serum_XY10.csv size: (42546, 67)\n",
      "features_PEG_XY01.csv\n",
      "features_PEG_XY01.csv size: (7397, 67)\n",
      "features_PEG_XY02.csv\n",
      "features_PEG_XY02.csv size: (5157, 67)\n",
      "features_PEG_XY03.csv\n",
      "features_PEG_XY03.csv size: (5922, 67)\n",
      "features_PEG_XY04.csv\n",
      "features_PEG_XY04.csv size: (9005, 67)\n",
      "features_PEG_XY05.csv\n",
      "features_PEG_XY05.csv size: (7906, 67)\n",
      "features_PEG_XY06.csv\n",
      "features_PEG_XY06.csv size: (13236, 67)\n",
      "features_PEG_XY07.csv\n",
      "features_PEG_XY07.csv size: (13785, 67)\n",
      "Skipped!: features_PEG_XY07.csv\n",
      "features_PEG_XY08.csv\n",
      "features_PEG_XY08.csv size: (14076, 67)\n",
      "features_PEG_XY09.csv\n",
      "features_PEG_XY09.csv size: (15334, 67)\n",
      "features_PEG_XY10.csv\n",
      "features_PEG_XY10.csv size: (12137, 67)\n",
      "features_PEG_serum_XY01.csv\n",
      "features_PEG_serum_XY01.csv size: (70521, 67)\n",
      "features_PEG_serum_XY02.csv\n",
      "features_PEG_serum_XY02.csv size: (71639, 67)\n",
      "features_PEG_serum_XY03.csv\n",
      "features_PEG_serum_XY03.csv size: (71496, 67)\n",
      "features_PEG_serum_XY04.csv\n",
      "features_PEG_serum_XY04.csv size: (69101, 67)\n",
      "features_PEG_serum_XY05.csv\n",
      "features_PEG_serum_XY05.csv size: (65176, 67)\n",
      "features_PEG_serum_XY06.csv\n",
      "features_PEG_serum_XY06.csv size: (66877, 67)\n",
      "features_PEG_serum_XY07.csv\n",
      "features_PEG_serum_XY07.csv size: (69408, 67)\n",
      "features_PEG_serum_XY08.csv\n",
      "features_PEG_serum_XY08.csv size: (71639, 67)\n",
      "features_PEG_serum_XY09.csv\n",
      "features_PEG_serum_XY09.csv size: (73978, 67)\n",
      "features_PEG_serum_XY10.csv\n",
      "features_PEG_serum_XY10.csv size: (74161, 67)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "featofvar = 'Type and Serum'\n",
    "\n",
    "remote_folder = '10_04_18_COOH_PEG_serum' #Folder in AWS S3 containing files to be analyzed\n",
    "bucket = 'rhodese.data'\n",
    "vids = 10\n",
    "types = ['COOH', 'COOH_serum', 'PEG', 'PEG_serum']\n",
    "\n",
    "counter2 = 0\n",
    "counter = 0\n",
    "for typ in types:\n",
    "    for num in range(1, vids+1):\n",
    "            try:\n",
    "                filename = 'features_{}_XY{}.csv'.format(typ, '%02d' % num)\n",
    "                print(filename)\n",
    "                aws.download_s3('{}/{}'.format(remote_folder, filename), filename, bucket_name=bucket)\n",
    "                fstats = pd.read_csv(filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "                print('{} size: {}'.format(filename, fstats.shape))\n",
    "                fstats['Type and Serum'] = pd.Series(fstats.shape[0]*[typ], index=fstats.index)\n",
    "                if 'serum' in typ:\n",
    "                    fstats['Serum'] = pd.Series(fstats.shape[0]*['serum'], index=fstats.index)\n",
    "                else:\n",
    "                    fstats['Serum'] = pd.Series(fstats.shape[0]*['no serum'], index=fstats.index)\n",
    "                if 'COOH' in typ:\n",
    "                    fstats['Type'] = pd.Series(fstats.shape[0]*['COOH'], index=fstats.index)\n",
    "                else:\n",
    "                    fstats['Type'] = pd.Series(fstats.shape[0]*['PEG'], index=fstats.index)\n",
    "                fstats['Video Number'] = pd.Series(fstats.shape[0]*[num], index=fstats.index)\n",
    "                counter = counter + 1\n",
    "                if counter == 1:\n",
    "                    fstats_tot = fstats\n",
    "                else:\n",
    "                    fstats_tot = fstats_tot.append(fstats, ignore_index=True)\n",
    "            except:\n",
    "                print('Skipped!: {}'.format(filename))\n",
    "    counter2 = counter2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/david/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "fstats_tot['LogDeff2'] = np.log(fstats_tot['Deff2']).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats_tot['LogMeanDeff2'] = np.log(fstats_tot['Mean Deff2']).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pcadataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cc5f92efbf44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpcadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogMeanDeff2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean Deff2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pcadataset' is not defined"
     ]
    }
   ],
   "source": [
    "pcadataset.final['LogMeanDeff2'] = np.log(pcadataset.final['Mean Deff2']).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pcadataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c55da3be425e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpcadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogMeanDeff1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean Deff1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pcadataset' is not defined"
     ]
    }
   ],
   "source": [
    "pcadataset.final['LogMeanDeff1'] = np.log(pcadataset.final['Mean Deff1']).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadataset.final['LogDeff2'] = np.log(pcadataset.final['Deff2']).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-10, 10, 200)\n",
    "axes = fstats_tot.hist(column='LogDeff2', by='Type and Serum', layout=(4, 1), bins=bins, sharex=True, sharey=True,\n",
    "                        figsize=(10, 8), edgecolor='k')\n",
    "\n",
    "means = []\n",
    "counter = 0\n",
    "#types2 = ['100', '200', '500']\n",
    "for ax, typ in zip(axes, types):\n",
    "    ax.set_ylim([0,4000])\n",
    "    #ax.set_xscale(\"log\", nonposx='clip')\n",
    "    ax.set_xlim([-7.5,3.5])\n",
    "    means.append(fstats_tot[fstats_tot['Type and Serum']==typ]['LogDeff2'].median())\n",
    "    ax.axvline(fstats_tot[fstats_tot['Type and Serum']==typ]['LogDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    counter = counter + 1\n",
    "    if counter == 4:\n",
    "        ax.set_xlabel(r'$log(D_{eff})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53a1bd0d12ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstats_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biny'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstats_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bins'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'biny'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfstats_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfstats_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstats_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "bins = list(range(0, 2048+1, 256))\n",
    "fstats_tot['binx'] = pd.cut(fstats_tot.X, bins, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "fstats_tot['biny'] = pd.cut(fstats_tot.Y, bins, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "fstats_tot['bins'] = 8*fstats_tot['binx'] + fstats_tot['biny']\n",
    "fstats_tot = fstats_tot[np.isfinite(fstats_tot.bins)]\n",
    "fstats_tot.bins = fstats_tot.bins.astype(int)\n",
    "\n",
    "cols = fstats_tot.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "fstats_tot = fstats_tot[cols]\n",
    "\n",
    "def checkerboard(size):\n",
    "    rows = int(size/2)\n",
    "    checks = list(range(0, size*size, size+1))\n",
    "    \n",
    "    for i in range(1, rows):\n",
    "        ssize = size - 2*i\n",
    "        for j in range(0, ssize):\n",
    "            checks.append(2*i + (size+1)*j)\n",
    "\n",
    "    for i in range(1, rows):\n",
    "        ssize = size - 2*i\n",
    "        for j in range(0, ssize):\n",
    "            checks.append(size*size - 1 - (2*i + (size+1)*j))\n",
    "    checks.sort()\n",
    "    return checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fstats_tot[fstats_tot.bins.isin(checkerboard(8))].reset_index()\n",
    "X_test = fstats_tot[~fstats_tot.bins.isin(checkerboard(8))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD = np.array(means)\n",
    "meanD.sort()\n",
    "Dbins = meanD[0:-1] + np.diff(meanD)/2\n",
    "print(Dbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Dbins = [-10, 0.806, 0.845, 1.109, 10]\n",
    "bins = np.linspace(-10, 10, 200)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 9))\n",
    "counter = 0\n",
    "means = []\n",
    "for ax in axes:\n",
    "    means.append(X_train[X_train['Type and Serum']==types[counter]]['LogDeff2'].median())\n",
    "    for i in range(4):\n",
    "        X_train[(X_train['Type and Serum']==types[counter]) & (Dbins[i] < X_train['LogDeff2']) & (X_train['LogDeff2'] < Dbins[i+1])].hist(column='LogDeff2', bins=bins, figsize=(12,3), edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-7.5, 3.5])\n",
    "        ax.set_ylim([0, 3000])\n",
    "    ax.axvline(X_train[X_train['Type and Serum']==types[counter]]['LogDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title(types[counter])\n",
    "    if counter == 3:\n",
    "        ax.set_xlabel(r'$log(D_{eff})$')\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dbins = [-10, 0.806, 0.845, 1.109, 10]\n",
    "bins = np.linspace(-10, 10, 200)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 9))\n",
    "counter = 0\n",
    "means = []\n",
    "for ax in axes:\n",
    "    means.append(X_test[X_test['Type and Serum']==types[counter]]['LogDeff2'].median())\n",
    "    for i in range(4):\n",
    "        X_test[(X_test['Type and Serum']==types[counter]) & (Dbins[i] < X_test['LogDeff2']) & (X_test['LogDeff2'] < Dbins[i+1])].hist(column='LogDeff2', bins=bins, figsize=(12,3), edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-7.5, 3.5])\n",
    "        ax.set_ylim([0, 3000])\n",
    "    ax.axvline(X_test[X_test['Type and Serum']==types[counter]]['LogDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title(types[counter])\n",
    "    if counter == 3:\n",
    "        ax.set_xlabel(r'$log(D_{eff})$')\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_train.LogDeff2.values, bins=[-10, 0.806, 0.845, 1.109, 10], labels=types).astype(str))\n",
    "y_true2 = X_train['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_test.LogDeff2.values, bins=[-10, 0.806, 0.845, 1.109, 10], labels=types).astype(str))\n",
    "y_true2 = X_test['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD = np.array(means)\n",
    "meanD.sort()\n",
    "Dbins = meanD[0:-1] + np.diff(meanD)/2\n",
    "print(Dbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dbins = [-10, 1.10, 1.262, 1.528, 10]\n",
    "bins = np.linspace(-10, 10, 200)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 9))\n",
    "counter = 0\n",
    "means = []\n",
    "for ax in axes:\n",
    "    means.append(X_train[X_train['Type and Serum']==types[counter]]['LogMeanDeff2'].median())\n",
    "    for i in range(4):\n",
    "        X_train[(X_train['Type and Serum']==types[counter]) & (Dbins[i] < X_train['LogMeanDeff2']) & (X_train['LogMeanDeff2'] < Dbins[i+1])].hist(column='LogMeanDeff2', bins=bins, figsize=(12,3), edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-7.5, 3.5])\n",
    "        ax.set_ylim([0, 15000])\n",
    "    ax.axvline(X_train[X_train['Type and Serum']==types[counter]]['LogMeanDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title(types[counter])\n",
    "    if counter == 3:\n",
    "        ax.set_xlabel(r'$log(D_{eff})$')\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dbins = [-10, 1.10, 1.262, 1.528, 10]\n",
    "bins = np.linspace(-10, 10, 200)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 9))\n",
    "counter = 0\n",
    "means = []\n",
    "for ax in axes:\n",
    "    means.append(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median())\n",
    "    for i in range(4):\n",
    "        X_test[(X_test['Type and Serum']==types[counter]) & (Dbins[i] < X_test['LogMeanDeff2']) & (X_test['LogMeanDeff2'] < Dbins[i+1])].hist(column='LogMeanDeff2', bins=bins, figsize=(12,3), edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-7.5, 3.5])\n",
    "        ax.set_ylim([0, 15000])\n",
    "    ax.axvline(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title(types[counter])\n",
    "    if counter == 3:\n",
    "        ax.set_xlabel(r'$log(D_{eff})$')\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "Dbins = [-10, 1.10, 1.262, 1.528, 10]\n",
    "bins = np.linspace(-10, 10, 400)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 14))\n",
    "counter = 0\n",
    "means = []\n",
    "labels3 = ['PS-PEG in serum', 'PS-COOH', 'PS-COOH in serum', 'PS-PEG']\n",
    "for ax in axes:\n",
    "    means.append(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median())\n",
    "    color = iter(newmap)\n",
    "    for i in range(4):\n",
    "        c = next(color)\n",
    "        X_test[(X_test['Type and Serum']==types[counter]) & (Dbins[i] < X_test['LogMeanDeff2']) & (X_test['LogMeanDeff2'] < Dbins[i+1])].hist(column='LogMeanDeff2', bins=bins, figsize=(12,3), label = labels3[3-i], color=c, alpha=0.85, edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-1, 3])\n",
    "        ax.set_ylim([0, 6000])\n",
    "        ax.tick_params(labelsize=16)\n",
    "    ax.axvline(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title('')\n",
    "    if counter == 0:\n",
    "        ax.legend(fontsize=17)\n",
    "#     if counter == 3:\n",
    "#         ax.set_xlabel(r'$log(\\bar{D}_{eff})$', fontsize=22)\n",
    "    if counter != 3:\n",
    "        ax.set_xticklabels([])\n",
    "    counter = counter + 1\n",
    "fig.savefig('./pics/corona_hist2.png', dpi=300, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['PEG_serum', 'COOH', 'COOH_serum', 'PEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmap = cm.viridis(np.linspace(0.9, 0.0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmap = cm.viridis(np.linspace(0.9, 0.0, 4))\n",
    "newmap[0:3, :] = cm.viridis(np.linspace(0.9, 0.0, 4))[1:4, :]\n",
    "newmap[3, :] = cm.viridis(np.linspace(0.9, 0.0, 4))[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "Dbins = [-10, 1.10, 1.262, 1.528, 10]\n",
    "bins = np.linspace(-10, 10, 400)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 14))\n",
    "counter = 0\n",
    "means = []\n",
    "labels3 = ['PS-PEG in serum', 'PS-COOH', 'PS-COOH in serum', 'PS-PEG']\n",
    "for ax in axes:\n",
    "    means.append(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median())\n",
    "    color = iter(newmap)\n",
    "    for i in range(4):\n",
    "        c = next(color)\n",
    "        X_test[(X_test['Type and Serum']==types[counter]) & (Dbins[i] < X_test['LogMeanDeff2']) & (X_test['LogMeanDeff2'] < Dbins[i+1])].hist(column='LogMeanDeff2', bins=bins, figsize=(9,3), label = labels3[3-i], color=c, alpha=0.85, edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-1, 3])\n",
    "        ax.set_ylim([0, 36000])\n",
    "        ax.tick_params(labelsize=16)\n",
    "    ax.axvline(X_test[X_test['Type and Serum']==types[counter]]['LogMeanDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title('')\n",
    "    if counter == 0:\n",
    "        ax.legend(fontsize=17)\n",
    "    ax.set_yticklabels([])\n",
    "#     if counter == 3:\n",
    "#         ax.set_xlabel(r'$log(\\bar{D}_{eff})$', fontsize=22)\n",
    "    if counter != 3:\n",
    "        ax.set_xticklabels([])\n",
    "    counter = counter + 1\n",
    "fig.savefig('./pics/corona_hist_redo.png', dpi=300, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['PEG_serum', 'COOH_serum', 'COOH', 'PEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "Dbins = [-10, 0.806, 0.845, 1.109, 10]\n",
    "bins = np.linspace(-10, 10, 400)\n",
    "fig, axes = plt.subplots(nrows=4, figsize=(12, 14))\n",
    "counter = 0\n",
    "means = []\n",
    "labels3 = ['PS-PEG in serum', 'PS-COOH', 'PS-COOH in serum', 'PS-PEG']\n",
    "for ax in axes:\n",
    "    means.append(X_test[X_test['Type and Serum']==types[counter]]['LogDeff2'].median())\n",
    "    color = iter(newmap)\n",
    "    for i in range(4):\n",
    "        c = next(color)\n",
    "        X_test[(X_test['Type and Serum']==types[counter]) & (Dbins[i] < X_test['LogDeff2']) & (X_test['LogDeff2'] < Dbins[i+1])].hist(column='LogDeff2', bins=bins, figsize=(9,3), label = labels3[3-i], color=c, alpha=0.85, edgecolor='k', ax=ax, )\n",
    "        ax.set_xlim([-1, 3])\n",
    "        ax.set_ylim([0, 3000])\n",
    "        ax.tick_params(labelsize=16)\n",
    "    ax.axvline(X_test[X_test['Type and Serum']==types[counter]]['LogDeff2'].median(), color='k', linestyle='dashed', linewidth=3)\n",
    "    ax.set_title('')\n",
    "    if counter == 0:\n",
    "        ax.legend(fontsize=17)\n",
    "    ax.set_yticklabels([])\n",
    "#     if counter == 3:\n",
    "#         ax.set_xlabel(r'$log(\\bar{D}_{eff})$', fontsize=22)\n",
    "    if counter != 3:\n",
    "        ax.set_xticklabels([])\n",
    "    counter = counter + 1\n",
    "#fig.savefig('./pics/corona_hist_redo.png', dpi=300, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_test.LogMeanDeff2.values, bins=[-10, 1.10, 1.262, 1.528, 10], labels=types).astype(str))\n",
    "y_true2 = X_test['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_test.LogDeff2.values, bins=[-10, 0.806, 0.845, 1.109, 10], labels=types).astype(str))\n",
    "y_true2 = X_test['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_train.LogDeff2.values, bins=[-10, 0.806, 0.845, 1.109, 10], labels=types).astype(str))\n",
    "y_true2 = X_train['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.viridis(np.linspace(0.9, 0.0, 4))[1:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmap = np.zeros((4,4))\n",
    "newmap[0:3, :] = cm.viridis(np.linspace(0.9, 0.0, 4))[1:4, :]\n",
    "newmap[3, :] = cm.viridis(np.linspace(0.9, 0.0, 4))[0, :]\n",
    "newmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_train.LogMeanDeff2.values, bins=[-10, 1.10, 1.262, 1.528, 10], labels=types).astype(str))\n",
    "y_true2 = X_train['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = list(pd.cut(X_test.LogMeanDeff2.values, bins=[-10, 1.10, 1.262, 1.528, 10], labels=types).astype(str))\n",
    "y_true2 = X_test['Type and Serum'].values\n",
    "\n",
    "print(classification_report(y_true2, y_pred2, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA analyses with too many datapoints fail. You get rows with lots of NAs. I'm going to try making a subset of the data first\n",
    "#and then do a PCA analysis on that.\n",
    "\n",
    "#include all in analysis\n",
    "import random\n",
    "subset = np.sort(np.array(random.sample(range(fstats_tot.shape[0]), 500000)))\n",
    "fstats_sub = fstats_tot.loc[subset, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COOH', 'COOH_serum', 'PEG', 'PEG_serum'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstats_tot['Type and Serum'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270235, 73)\n",
      "(383602, 73)\n",
      "(103955, 73)\n",
      "(703996, 73)\n"
     ]
    }
   ],
   "source": [
    "for typ in fstats_tot['Type and Serum'].unique():\n",
    "    fstats_type = fstats_tot[fstats_tot['Type and Serum']==typ].reset_index(drop=True)\n",
    "    print(fstats_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270235, 73)\n",
      "(383602, 73)\n",
      "(103955, 73)\n",
      "(703996, 73)\n"
     ]
    }
   ],
   "source": [
    "#with equal sample sizes for each particle type\n",
    "import random\n",
    "counter = 0\n",
    "for typ in fstats_tot['Type and Serum'].unique():\n",
    "    fstats_type = fstats_tot[fstats_tot['Type and Serum']==typ].reset_index(drop=True)\n",
    "    print(fstats_type.shape)\n",
    "    subset = np.sort(np.array(random.sample(range(fstats_type.shape[0]), 50000)))\n",
    "    if counter == 0:\n",
    "        fstats_sub = fstats_type.loc[subset, :].reset_index(drop=True)\n",
    "    else:\n",
    "        fstats_sub = fstats_sub.append(fstats_type.loc[subset, :].reset_index(drop=True), ignore_index=True)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/david/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#fstats = pd.read_csv(filename, encoding = \"ISO-8859-1\", index_col='Unnamed: 0')\n",
    "nonnum = ['Type and Serum', 'Type', 'Serum', 'Video Number', 'Track_ID', 'Mean Mean_Intensity', 'Std Mean_Intensity', 'X', 'Y',\n",
    "          'Mean X', 'Mean Y', 'Std X', 'Std Y']\n",
    "fstats_num = fstats_sub.drop(nonnum, axis=1)\n",
    "fstats_raw = fstats_num.as_matrix()\n",
    "#fstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pca.pca_analysis function provides a completely contained PCA analysis of the input trajectory features dataset. It includes options to impute NaN values (fill in with average values or drop them), and to scale features. Read the docstring for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/david/lib/python3.7/site-packages/scikit_learn-0.20.3-py3.7-linux-x86_64.egg/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative explained variance:\n",
      "0 component: 0.19930512724585375\n",
      "1 component: 0.30168896917702254\n",
      "2 component: 0.40255233652119876\n",
      "3 component: 0.4858259172790418\n",
      "4 component: 0.5341055250351264\n",
      "5 component: 0.5795016763195652\n",
      "6 component: 0.6198510372497357\n",
      "7 component: 0.6580721763503102\n",
      "8 component: 0.6893828592036572\n",
      "9 component: 0.7176706996302213\n",
      "10 component: 0.7438810435982376\n",
      "11 component: 0.7689922902470988\n",
      "12 component: 0.7905518348222168\n",
      "13 component: 0.8107422972165624\n"
     ]
    }
   ],
   "source": [
    "ncomp = 14\n",
    "pcadataset = pca.pca_analysis(fstats_tot, dropcols=nonnum, n_components=ncomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadataset.components.to_csv('components.csv')\n",
    "aws.upload_s3('components.csv', '{}/components.csv'.format(remote_folder, filename), bucket_name=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alpha', 'D_fit', 'kurtosis', 'asymmetry1', 'asymmetry2', 'asymmetry3',\n",
       "       'AR', 'elongation', 'boundedness', 'fractal_dim', 'trappedness',\n",
       "       'efficiency', 'straightness', 'MSD_ratio', 'frames', 'Quality',\n",
       "       'Mean_Intensity', 'SN_Ratio', 'Deff1', 'Deff2', 'Mean alpha',\n",
       "       'Std alpha', 'Mean D_fit', 'Std D_fit', 'Mean kurtosis', 'Std kurtosis',\n",
       "       'Mean asymmetry1', 'Std asymmetry1', 'Mean asymmetry2',\n",
       "       'Std asymmetry2', 'Mean asymmetry3', 'Std asymmetry3', 'Mean AR',\n",
       "       'Std AR', 'Mean elongation', 'Std elongation', 'Mean boundedness',\n",
       "       'Std boundedness', 'Mean fractal_dim', 'Std fractal_dim',\n",
       "       'Mean trappedness', 'Std trappedness', 'Mean efficiency',\n",
       "       'Std efficiency', 'Mean straightness', 'Std straightness',\n",
       "       'Mean MSD_ratio', 'Std MSD_ratio', 'Mean frames', 'Std frames',\n",
       "       'Mean Quality', 'Std Quality', 'Mean SN_Ratio', 'Std SN_Ratio',\n",
       "       'Mean Deff1', 'Std Deff1', 'Mean Deff2', 'Std Deff2', 'LogDeff2',\n",
       "       'LogMeanDeff2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstats_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Quality</td>\n",
       "      <td>Std AR</td>\n",
       "      <td>asymmetry3</td>\n",
       "      <td>Mean asymmetry1</td>\n",
       "      <td>Mean straightness</td>\n",
       "      <td>Mean D_fit</td>\n",
       "      <td>straightness</td>\n",
       "      <td>Std frames</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Mean Deff1</td>\n",
       "      <td>Mean_Intensity</td>\n",
       "      <td>Std frames</td>\n",
       "      <td>Deff1</td>\n",
       "      <td>Mean efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Std elongation</td>\n",
       "      <td>Std boundedness</td>\n",
       "      <td>asymmetry2</td>\n",
       "      <td>Mean kurtosis</td>\n",
       "      <td>Std asymmetry2</td>\n",
       "      <td>Std straightness</td>\n",
       "      <td>D_fit</td>\n",
       "      <td>Deff1</td>\n",
       "      <td>asymmetry1</td>\n",
       "      <td>SN_Ratio</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Deff2</td>\n",
       "      <td>Deff2</td>\n",
       "      <td>Std frames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean MSD_ratio</td>\n",
       "      <td>Mean D_fit</td>\n",
       "      <td>AR</td>\n",
       "      <td>Mean asymmetry2</td>\n",
       "      <td>Std straightness</td>\n",
       "      <td>Std asymmetry2</td>\n",
       "      <td>fractal_dim</td>\n",
       "      <td>Std fractal_dim</td>\n",
       "      <td>asymmetry2</td>\n",
       "      <td>kurtosis</td>\n",
       "      <td>Deff2</td>\n",
       "      <td>Mean trappedness</td>\n",
       "      <td>Std MSD_ratio</td>\n",
       "      <td>Std MSD_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Std Quality</td>\n",
       "      <td>Mean boundedness</td>\n",
       "      <td>asymmetry1</td>\n",
       "      <td>Std asymmetry3</td>\n",
       "      <td>Std boundedness</td>\n",
       "      <td>Std D_fit</td>\n",
       "      <td>elongation</td>\n",
       "      <td>fractal_dim</td>\n",
       "      <td>D_fit</td>\n",
       "      <td>AR</td>\n",
       "      <td>D_fit</td>\n",
       "      <td>Mean fractal_dim</td>\n",
       "      <td>Mean fractal_dim</td>\n",
       "      <td>Mean trappedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frames</td>\n",
       "      <td>Mean efficiency</td>\n",
       "      <td>boundedness</td>\n",
       "      <td>Std kurtosis</td>\n",
       "      <td>Std AR</td>\n",
       "      <td>Mean AR</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>elongation</td>\n",
       "      <td>kurtosis</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Deff1</td>\n",
       "      <td>Mean elongation</td>\n",
       "      <td>Mean elongation</td>\n",
       "      <td>Std straightness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                 1            2                3   \\\n",
       "0    Mean Quality            Std AR   asymmetry3  Mean asymmetry1   \n",
       "1  Std elongation   Std boundedness   asymmetry2    Mean kurtosis   \n",
       "2  Mean MSD_ratio        Mean D_fit           AR  Mean asymmetry2   \n",
       "3     Std Quality  Mean boundedness   asymmetry1   Std asymmetry3   \n",
       "4          frames   Mean efficiency  boundedness     Std kurtosis   \n",
       "\n",
       "                  4                 5             6                7   \\\n",
       "0  Mean straightness        Mean D_fit  straightness       Std frames   \n",
       "1     Std asymmetry2  Std straightness         D_fit            Deff1   \n",
       "2   Std straightness    Std asymmetry2   fractal_dim  Std fractal_dim   \n",
       "3    Std boundedness         Std D_fit    elongation      fractal_dim   \n",
       "4             Std AR           Mean AR    efficiency       elongation   \n",
       "\n",
       "           8           9               10                11                12  \\\n",
       "0       alpha  Mean Deff1  Mean_Intensity        Std frames             Deff1   \n",
       "1  asymmetry1    SN_Ratio         Quality             Deff2             Deff2   \n",
       "2  asymmetry2    kurtosis           Deff2  Mean trappedness     Std MSD_ratio   \n",
       "3       D_fit          AR           D_fit  Mean fractal_dim  Mean fractal_dim   \n",
       "4    kurtosis     Quality           Deff1   Mean elongation   Mean elongation   \n",
       "\n",
       "                 13  \n",
       "0   Mean efficiency  \n",
       "1        Std frames  \n",
       "2     Std MSD_ratio  \n",
       "3  Mean trappedness  \n",
       "4  Std straightness  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcadataset.prcomps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pca.kmo function calculates the Kaiser-Meyer-Olkin statistic, a measure of sampling adequacy. Check the docstring for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e63b2302242a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkmostat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/david/lib/python3.7/site-packages/diff_classifier/pca.py\u001b[0m in \u001b[0;36mkmo\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Correlation matrix and the partial covariance matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcorrmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mpcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Calculation of the KMO statistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/david/lib/python3.7/site-packages/diff_classifier/pca.py\u001b[0m in \u001b[0;36mpartial_corr\u001b[0;34m(mtrx)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mbeta_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtrx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtrx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mbeta_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtrx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtrx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/david/lib/python3.7/site-packages/scipy-1.2.1-py3.7-linux-x86_64.egg/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[0;32m-> 1234\u001b[0;31m                                                iwork, cond, False, False)\n\u001b[0m\u001b[1;32m   1235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# complex data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m                 lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kmostat = pca.kmo(pcadataset.scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can then compare average principle component values between subgroups of the data. In this case, all particles were taken from the same sample, so there are no experimental subgroups. I chose to compare short trajectories to long trajectories, as I would expect differences between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "featofvar = 'Type and Serum'\n",
    "#ncomp = 14\n",
    "dicti = {}\n",
    "#test = np.exp(np.nanmean(np.log(pcadataset.final[pcadataset.final['Particle Size']==200].as_matrix()), axis=0))[-6:]\n",
    "#test1 = np.exp(np.nanmean(np.log(pcadataset.final[pcadataset.final['Particle Size']==500].as_matrix()), axis=0))[-6:]\n",
    "dicti[0] = np.nanmean(pcadataset.final[pcadataset.final[featofvar]=='COOH'].values[:, -ncomp:], axis=0)\n",
    "dicti[1] = np.nanmean(pcadataset.final[pcadataset.final[featofvar]=='COOH_serum'].values[:, -ncomp:], axis=0)\n",
    "dicti[2] = np.nanmean(pcadataset.final[pcadataset.final[featofvar]=='PEG'].values[:, -ncomp:], axis=0)\n",
    "dicti[3] = np.nanmean(pcadataset.final[pcadataset.final[featofvar]=='PEG_serum'].values[:, -ncomp:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['COOH', 'COOH_serum', 'PEG', 'PEG_serum']\n",
    "pca.plot_pca(dicti, savefig=True, labels=labels, rticks=np.linspace(-4, 4, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['COOH', 'COOH_serum', 'PEG', 'PEG_serum']\n",
    "pca.plot_pca(dicti, savefig=True, labels=labels, rticks=np.linspace(-4, 4, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable pcadataset.prcomps shows the user the major contributions to each of the new principle components. When observing the graph above, users can see that there are some differences between short trajectories and long trajectories in component 0 (asymmetry1 being the major contributor) and component 1 (elongation being the major contributor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels=['10K', '5K', '1K', 'COOH']\n",
    "feats = pca.feature_violin(pcadataset.final, label=featofvar, lvals=labels, fsubset=ncomp, yrange=[-12, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "def feature_violin(df, label='label', lvals=['yes', 'no'], labels=['yes', 'no'], fsubset=3, **kwargs):\n",
    "    \"\"\"Creates violinplot of input feature dataset\n",
    "\n",
    "    Designed to plot PCA components from pca_analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frames.DataFrame\n",
    "        Must contain a group name column, and numerical feature columns.\n",
    "    label : string or int\n",
    "        Name of group column.\n",
    "    lvals : list of string or int\n",
    "        All values that group column can take\n",
    "    fsubset : int or list of int\n",
    "        Features to be plotted. If integer, will plot range(fsubset).\n",
    "        If list, will only plot features contained in fsubset.\n",
    "    **kwargs : variable\n",
    "        figsize : tuple of int or float\n",
    "            Dimensions of output figure\n",
    "        yrange : list of int or float\n",
    "            Range of y axis\n",
    "        xlabel : string\n",
    "            Label of x axis\n",
    "        labelsize : int or float\n",
    "            Font size of x label\n",
    "        ticksize : int or float\n",
    "            Font size of y tick labels\n",
    "        fname : None or string\n",
    "            Name of output file\n",
    "        legendfontsize : int or float\n",
    "            Font size of legend\n",
    "        legendloc : int\n",
    "            Location of legend in plot e.g. 1, 2, 3, 4\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    defaults = {'figsize': (12, 5), 'yrange': [-20, 20], 'xlabel': 'Feature',\n",
    "                'labelsize': 20, 'ticksize': 16, 'fname': None,\n",
    "                'legendfontsize': 12, 'legendloc': 1}\n",
    "\n",
    "    for defkey in defaults.keys():\n",
    "        if defkey not in kwargs.keys():\n",
    "            kwargs[defkey] = defaults[defkey]\n",
    "\n",
    "    # Restacking input data\n",
    "    groupsize = []\n",
    "    featcol = []\n",
    "    valcol = []\n",
    "    feattype = []\n",
    "\n",
    "    if isinstance(fsubset, int):\n",
    "        frange = range(fsubset)\n",
    "    else:\n",
    "        frange = fsubset\n",
    "\n",
    "    for feat in frange:\n",
    "        groupsize.extend(df[label].values)\n",
    "        featcol.extend([feat]*df[label].values.shape[0])\n",
    "        valcol.extend(df[feat].values)\n",
    "\n",
    "    to_violind = {'label': groupsize, 'Feature': featcol,\n",
    "                  'Feature Value': valcol}\n",
    "    to_violin = pd.DataFrame(data=to_violind)\n",
    "\n",
    "    # Plotting function\n",
    "    fig, ax = plt.subplots(figsize=kwargs['figsize'])\n",
    "    sns.violinplot(x=\"Feature\", y=\"Feature Value\", hue=\"label\", data=to_violin,\n",
    "                   palette=cm.viridis(np.linspace(0, 0.9, 4)), hue_order=lvals,\n",
    "                   figsize=kwargs['figsize'], linewidth=0)\n",
    "\n",
    "    # kwargs\n",
    "    ax.tick_params(axis='both', which='major', labelsize=kwargs['ticksize'])\n",
    "    plt.xlabel('Feature', fontsize=kwargs['labelsize'])\n",
    "    plt.ylabel('Normalized\\nFeature Space', fontsize=kwargs['labelsize'])\n",
    "    plt.ylim(kwargs['yrange'])\n",
    "    plt.setp(ax.collections, alpha=.75)\n",
    "    L=ax.legend(prop={'size': 18})\n",
    "    for item, label in zip(L.get_texts(), labels):\n",
    "        item.set_text(label)\n",
    "    #ax.legend(prop={'size': 18})\n",
    "    \n",
    "    if kwargs['fname'] is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(kwargs['fname'], dpi=300, pad_inches=0.22)\n",
    "\n",
    "    return to_violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = ['PS-COOH', 'PS-COOH in serum', 'PS-PEG', 'PS-PEG in serum']\n",
    "feats = feature_violin(pcadataset.final, label='Type and Serum', lvals=labels, labels=labels2, fsubset=14, yrange=[-14, 14],\n",
    "                       legendfontsize=21, labelsize=24, fname='./pics/corona_pcadist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats1 = pca.feature_plot_3D(pcadataset.final, label=featofvar, lvals=labels, randcount=400, ylim=[-12, 12],\n",
    "                              xlim=[-12, 12], zlim=[-12, 12], features=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats1 = pca.feature_plot_3D(pcadataset.final, label='Serum', lvals=['serum', 'no serum'], randcount=800, ylim=[-12, 12],\n",
    "                              xlim=[-12, 12], zlim=[-12, 12], features=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats1 = pca.feature_plot_3D(pcadataset.final, label='Type', lvals=['COOH', 'PEG'], randcount=800, ylim=[-12, 12],\n",
    "                              xlim=[-12, 12], zlim=[-12, 12], features=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pcadataset.final.values[:, -ncomp:]\n",
    "y = pcadataset.final[featofvar].values\n",
    "for run in range(1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(test, y, test_size=0.4)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(900, ), solver='sgd', verbose=True, max_iter=500, tol=0.00001,\n",
    "                        alpha=0.001, batch_size=50, learning_rate_init=0.005, learning_rate='adaptive',\n",
    "                        early_stopping=True, validation_fraction=0.1)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Training Results')\n",
    "    y_true1, y_pred1 = y_train, clf.predict(X_train)\n",
    "    print(classification_report(y_true1, y_pred1))\n",
    "    \n",
    "    print('Test Results')\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Results')\n",
    "y_true1, y_pred1 = y_train, clf.predict(X_train)\n",
    "print(classification_report(y_true1, y_pred1, digits=4))\n",
    "\n",
    "print('Test Results')\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(clf.loss_curve_, linewidth=4)\n",
    "#ax1.set_xlim([0, 60])\n",
    "#ax1.set_ylim([0.04, 0.18])\n",
    "ax1.set_ylabel('Loss Curve')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(clf.validation_scores_, linewidth=4, c='g')\n",
    "#ax2.set_ylim([0.94, 0.99])\n",
    "ax2.set_ylabel('Validation Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 2048+1, 256))\n",
    "pcadataset.final['binx'] = pd.cut(pcadataset.final.X, bins, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "pcadataset.final['biny'] = pd.cut(pcadataset.final.Y, bins, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "pcadataset.final['bins'] = 8*pcadataset.final['binx'] + pcadataset.final['biny']\n",
    "pcadataset.final = pcadataset.final[np.isfinite(pcadataset.final.bins)]\n",
    "pcadataset.final.bins = pcadataset.final.bins.astype(int)\n",
    "\n",
    "cols = pcadataset.final.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "pcadataset.final = pcadataset.final[cols]\n",
    "\n",
    "def checkerboard(size):\n",
    "    rows = int(size/2)\n",
    "    checks = list(range(0, size*size, size+1))\n",
    "    \n",
    "    for i in range(1, rows):\n",
    "        ssize = size - 2*i\n",
    "        for j in range(0, ssize):\n",
    "            checks.append(2*i + (size+1)*j)\n",
    "\n",
    "    for i in range(1, rows):\n",
    "        ssize = size - 2*i\n",
    "        for j in range(0, ssize):\n",
    "            checks.append(size*size - 1 - (2*i + (size+1)*j))\n",
    "    checks.sort()\n",
    "    return checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featofvar = 'Type and Serum'\n",
    "#ncomp = 16\n",
    "\n",
    "X_train = pcadataset.final[pcadataset.final.bins.isin(checkerboard(8))].values[:, -ncomp:]\n",
    "X_test = pcadataset.final[~pcadataset.final.bins.isin(checkerboard(8))].values[:, -ncomp:]\n",
    "y_train = pcadataset.final[pcadataset.final.bins.isin(checkerboard(8))][featofvar].values\n",
    "y_test = pcadataset.final[~pcadataset.final.bins.isin(checkerboard(8))][featofvar].values\n",
    "\n",
    "for run in range(1):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(900, ), solver='sgd', verbose=True, max_iter=500, tol=0.00001,\n",
    "                        alpha=0.001, batch_size=50, learning_rate_init=0.005, learning_rate='adaptive',\n",
    "                        early_stopping=True, validation_fraction=0.1)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Training Results')\n",
    "    y_true1, y_pred1 = y_train, clf.predict(X_train)\n",
    "    print(classification_report(y_true1, y_pred1, digits=4))\n",
    "    \n",
    "    print('Test Results')\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncomp = 14\n",
    "trainp = np.array([])\n",
    "testp = np.array([])\n",
    "labels3 = ['COOH', 'PEG']\n",
    "labels = ['COOH', 'COOH_serum', 'PEG', 'PEG_serum']\n",
    "\n",
    "for i in range(0, 3):\n",
    "    KNNmod, X, y = pca.build_model(pcadataset.final, featofvar, labels, equal_sampling=True,\n",
    "                                       tsize=2000, input_cols=ncomp, model='MLP', NNhidden_layer=(6, 5, 3))\n",
    "    trainp = np.append(trainp, pca.predict_model(KNNmod, X, y))\n",
    "    \n",
    "    X2 = pcadataset.final.values[:, -ncomp:]\n",
    "    y2 = pcadataset.final[featofvar].values\n",
    "    testp = np.append(testp, pca.predict_model(KNNmod, X2, y2))\n",
    "    print('Run {}: {}'.format(i, testp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncomp = 14\n",
    "trainp = np.array([])\n",
    "testp = np.array([])\n",
    "labels3 = ['COOH', 'PEG']\n",
    "labels = ['COOH', 'COOH_serum', 'PEG', 'PEG_serum']\n",
    "\n",
    "for i in range(0, 5):\n",
    "    KNNmod, X, y = pca.build_model(pcadataset.final, featofvar, labels, equal_sampling=True,\n",
    "                                       tsize=2000, input_cols=ncomp, model='MLP', NNhidden_layer=(6, 5, 3))\n",
    "    trainp = np.append(trainp, pca.predict_model(KNNmod, X, y))\n",
    "    \n",
    "    X2 = pcadataset.final.values[:, -ncomp:]\n",
    "    y2 = pcadataset.final[featofvar].values\n",
    "    testp = np.append(testp, pca.predict_model(KNNmod, X2, y2))\n",
    "    print('Run {}: {}'.format(i, testp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} +/ {}'.format(np.mean(trainp), np.std(trainp)))\n",
    "print('{} +/ {}'.format(np.mean(testp), np.std(testp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = pd.Series(KNNmod.predict(X2)).str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = np.copy(yact[0].values)\n",
    "ya[ya == 'COOH'] = 1\n",
    "ya[ya != 1] = 0\n",
    "\n",
    "yp = np.copy(ypred[0].values)\n",
    "yp[yp == 'COOH'] = 1\n",
    "yp[yp != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def mod_roc_curve(y_true, y_score, pos_label):\n",
    "    ya = np.copy(y_true)\n",
    "    ya[ya == pos_label] = 1\n",
    "    ya[ya != 1] = 0\n",
    "\n",
    "    yp = np.copy(y_score)\n",
    "    yp[yp == pos_label] = 1\n",
    "    yp[yp != 1] = 0\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(ya, yp, drop_intermediate=False)\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = mod_roc_curve(yact[1].values, ypred[1].values, pos_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr1 = np.random.randint(0, 2, size=400)\n",
    "yr2 = np.random.rand(400)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yr1, yr2)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 10\n",
    "size = 400\n",
    "yr1 = np.random.randint(0, 2, size=size)\n",
    "yr2 = yr1 + noise*np.random.rand(size) - 0.5*noise\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yr1, yr2)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 5\n",
    "size = 400\n",
    "yr1 = np.random.randint(0, 2, size=size)\n",
    "yr2 = yr1 + noise*np.random.rand(size) - 0.5*noise\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yr1, yr2)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 2.5\n",
    "size = 400\n",
    "yr1 = np.random.randint(0, 2, size=size)\n",
    "yr2 = yr1 + noise*np.random.rand(size) - 0.5*noise\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yr1, yr2)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 1.5\n",
    "size = 400\n",
    "yr1 = np.random.randint(0, 2, size=size)\n",
    "yr2 = yr1 + noise*np.random.rand(size) - 0.5*noise\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yr1, yr2)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNmod.score(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = label_binarize(y, classes=labels)\n",
    "y2new = label_binarize(y2, classes=labels)\n",
    "n_classes = ynew.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = classifier.fit(X, ynew).decision_function(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scorep = pd.DataFrame(data=y_score.transpose()).idxmax()\n",
    "y2newp = pd.DataFrame(data=y2new.transpose()).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycorrect = y_scorep == y2newp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycorrect.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(y2new[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y2new.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclass = 0\n",
    "plt.figure()\n",
    "lw = 4\n",
    "plt.plot(fpr[tclass], tpr[tclass], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[tclass])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X2, y2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc[0]*roc_auc[1]*roc_auc[2]*roc_auc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'slategray'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0, 0.4])\n",
    "plt.ylim([0.5, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found a standard way of implementing ROC curves with non-binary data called the one versus all method. It essentially breaks a n-class system into n-1 binary systems, and you make an n-1 roc curves for each case. I can't use MLP methods this way, but it looks like I can get high predictive power as-is? Kind of? I can get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot.shap(data, shap_contrib = NULL, \n",
    "              features = NULL, top_n = 1,\n",
    "              model = NULL, trees = NULL, \n",
    "              target_class = NULL,\n",
    "              approxcontrib = FALSE, subsample = NULL, \n",
    "              n_col = 1, col = rgb(0, 0, 1, 0.2), \n",
    "              pch = \".\", discrete_n_uniq = 5, \n",
    "              discrete_jitter = 0.01,\n",
    "              ylab = \"SHAP\", plot_NA = TRUE, \n",
    "              col_NA = rgb(0.7, 0, 1, 0.6),\n",
    "              pch_NA = \".\", pos_NA = 1.07, \n",
    "              plot_loess = TRUE, col_loess = 2,\n",
    "              span_loess = 0.5, which = c(\"1d\", \"2d\"), \n",
    "              plot = TRUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
