{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_classifier.aws as aws\n",
    "import diff_classifier.utils as ut\n",
    "import diff_classifier.msd as msd\n",
    "import diff_classifier.features as ft\n",
    "import diff_classifier.imagej as ij\n",
    "import diff_classifier.heatmaps as hm\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import skimage.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and checking a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = sio.imread('{}_3_3.tif'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws.download_s3('{}/{}.tif'.format(remote_folder, prefix), '{}.tif'.format(prefix))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "full_image = sio.imread('{}.tif'.format(prefix))\n",
    "ax.imshow(full_image[650, :, :], cmap='gray', vmin=60, vmax=500)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.imshow(test_image[650, :, :], cmap='gray', vmin=60, vmax=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.imshow(test_image[0, :, :], cmap='gray', vmin=60, vmax=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting images before analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'P2_S1_R_0009'\n",
    "remote_folder = \"01_18_Experiment/{}\".format(prefix.split('_')[0])\n",
    "local_folder = os.getcwd()\n",
    "ires = 512\n",
    "frames = 651\n",
    "filename = '{}.tif'.format(prefix)\n",
    "remote_name = op.join(remote_folder, filename)\n",
    "local_name = op.join(local_folder, filename)\n",
    "\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ij.partition_im?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(0, 4):\n",
    "    for j in range(0, 4):\n",
    "        names.append('{}_{}_{}.tif'.format(prefix, i, j))\n",
    "\n",
    "try:\n",
    "    for name in names:\n",
    "        aws.download_s3(remote_folder+'/'+name, name)\n",
    "except:\n",
    "    aws.download_s3(remote_name, local_name)\n",
    "    names = ij.partition_im(local_name)\n",
    "    for name in names:\n",
    "        #aws.upload_s3(name, op.join(remote_folder, name))\n",
    "        print(\"Done with splitting.  Should output file of name {}\".format(remote_folder+'/'+name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause here to demonstrate tracking with the Trackmate GUI.  Show the Trackmate template file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ij.track?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = 'Traj_' + names[15].split('.')[0] + '.csv'\n",
    "# row = int(names[15].split('.')[0].split('_')[4])\n",
    "# local_im = op.join(local_folder, names[15])\n",
    "# row=3\n",
    "\n",
    "# test_intensity = ij.mean_intensity(local_im)\n",
    "# if test_intensity > 500:\n",
    "#     quality = 245\n",
    "# else:\n",
    "#     quality = 4.5\n",
    "    \n",
    "# if row==3:\n",
    "#     y = 500\n",
    "# else:\n",
    "#     y = 511\n",
    "\n",
    "# ij.track(local_im, outfile, template=None, fiji_bin=None, radius=4.5, threshold=0., \n",
    "#       do_median_filtering=True, quality=quality, x=511, y=y, ylo=1, median_intensity=300.0, snr=0.0, \n",
    "#       linking_max_distance=8.0, gap_closing_max_distance=10.0, max_frame_gap=2,\n",
    "#       track_displacement=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    outfile = 'Traj_' + name.split('.')[0] + '.csv'\n",
    "    local_im = op.join(local_folder, name)\n",
    "    \n",
    "    row = int(name.split('.')[0].split('_')[4])\n",
    "    col = int(name.split('.')[0].split('_')[5])\n",
    "\n",
    "#     try:\n",
    "#         aws.download_s3(remote_folder+'/'+outfile, outfile)\n",
    "#     except:\n",
    "    test_intensity = ij.mean_intensity(local_im)\n",
    "    if test_intensity > 500:\n",
    "        quality = 245\n",
    "    else:\n",
    "        quality = 4.5\n",
    "        \n",
    "    if row==3:\n",
    "        y = 485\n",
    "    else:\n",
    "        y = 511\n",
    "\n",
    "    ij.track(local_im, outfile, template=None, fiji_bin=None, radius=4.5, threshold=0., \n",
    "          do_median_filtering=True, quality=quality, x=511, y=y, ylo=1, median_intensity=300.0, snr=0.0, \n",
    "          linking_max_distance=8.0, gap_closing_max_distance=10.0, max_frame_gap=2,\n",
    "          track_displacement=10.0)\n",
    "\n",
    "    aws.upload_s3(outfile, remote_folder+'/'+outfile)\n",
    "    print(\"Done with tracking.  Should output file of name {}\".format(remote_folder+'/'+outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating MSDs and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msd.all_msds2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"Traj_{}_{}_{}.csv\".format(prefix, row, col)\n",
    "# local_name = local_folder+'/'+filename\n",
    "\n",
    "# merged = msd.all_msds2(ut.csv_to_pd(local_name), frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_ft = ft.calculated_features(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_file = 'msd_{}.csv'.format(prefix)\n",
    "ft_file = 'features_{}.csv'.format(prefix)\n",
    "\n",
    "counter = 0\n",
    "for name in names:\n",
    "    row = int(name.split('.')[0].split('_')[4])\n",
    "    col = int(name.split('.')[0].split('_')[5])\n",
    "\n",
    "    filename = \"Traj_{}_{}_{}.csv\".format(prefix, row, col)\n",
    "    local_name = local_folder+'/'+filename\n",
    "\n",
    "    if counter == 0:\n",
    "        to_add = ut.csv_to_pd(local_name)\n",
    "        to_add['X'] = to_add['X'] + ires*col\n",
    "        to_add['Y'] = ires - to_add['Y'] + ires*(3-row)\n",
    "        merged = msd.all_msds2(to_add, frames=frames)\n",
    "    else: \n",
    "\n",
    "        if merged.shape[0] > 0:\n",
    "            to_add = ut.csv_to_pd(local_name)\n",
    "            to_add['X'] = to_add['X'] + ires*col\n",
    "            to_add['Y'] = ires - to_add['Y'] + ires*(3-row)\n",
    "            to_add['Track_ID'] = to_add['Track_ID'] + max(merged['Track_ID']) + 1\n",
    "        else:\n",
    "            to_add = ut.csv_to_pd(local_name)\n",
    "            to_add['X'] = to_add['X'] + ires*col\n",
    "            to_add['Y'] = ires - to_add['Y'] + ires*(3-row)\n",
    "            to_add['Track_ID'] = to_add['Track_ID']\n",
    "\n",
    "        merged = merged.append(msd.all_msds2(to_add, frames=frames))\n",
    "        print('Done calculating MSDs for row {} and col {}'.format(row, col))\n",
    "    counter = counter + 1\n",
    "\n",
    "merged.to_csv(msd_file)\n",
    "aws.upload_s3(msd_file, remote_folder+'/'+msd_file)\n",
    "merged_ft = ft.calculate_features(merged)\n",
    "merged_ft.to_csv(ft_file)\n",
    "aws.upload_s3(ft_file, remote_folder+'/'+ft_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = pd.read_csv('msd_{}.csv'.format(prefix))\n",
    "# merged_ft = pd.read_csv('features_{}.csv'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_trajectories(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ('AR', 'D_fit', 'alpha', 'MSD_ratio', 'Track_ID', 'X', 'Y', 'asymmetry1', 'asymmetry2', 'asymmetry3',\n",
    "#             'boundedness', 'efficiency', 'elongation', 'fractal_dim', 'frames', 'kurtosis', 'straightness', 'trappedness')\n",
    "\n",
    "# for feature in features:\n",
    "#     print('10th percentile of {}: {}'.format(feature, merged_ft[feature].quantile(0.1)))\n",
    "#     print('90th percentile of {}: {}'.format(feature, merged_ft[feature].quantile(0.9)))\n",
    "    \n",
    "#     hm.plot_heatmap(prefix, feature=feature, vmin=merged_ft[feature].quantile(0.1), vmax=merged_ft[feature].quantile(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ('AR', 'D_fit', 'alpha', 'MSD_ratio', 'Track_ID', 'X', 'Y', 'asymmetry1', 'asymmetry2', 'asymmetry3',\n",
    "#             'boundedness', 'efficiency', 'elongation', 'fractal_dim', 'frames', 'kurtosis', 'straightness', 'trappedness')\n",
    "# vmin = (1.36, 0.015, 0.72, -0.09, 0, 0, 0, 0.5, 0.049, 0.089, 0.0069, 0.65, 0.26, 1.28, 0, 1.66, 0.087, -0.225)\n",
    "# vmax = (3.98, 2.6, 2.3, 0.015, max(merged_ft['Track_ID']), 2048, 2048, 0.99, 0.415, 0.53, 0.062, 3.44, 0.75, 1.79, 650, 3.33, 0.52, -0.208)\n",
    "\n",
    "# die = {'features': features,\n",
    "#        'vmin': vmin,\n",
    "#        'vmax': vmax}\n",
    "# di = pd.DataFrame(data=die)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, di.shape[0]):\n",
    "#     hm.plot_heatmap(prefix, feature=di['features'][i], vmin=di['vmin'][i], vmax=di['vmax'][i])\n",
    "#     hm.plot_scatterplot(prefix, feature=di['features'][i], vmin=di['vmin'][i], vmax=di['vmax'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'efficiency'\n",
    "hm.plot_heatmap(prefix, feature=feature, vmin=merged_ft[feature].quantile(0.1), vmax=merged_ft[feature].quantile(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(4, 4, figsize=(14, 14))\n",
    "# for row in range(0, 2):\n",
    "#     for col in range(0, 4):\n",
    "#         subimage = sio.imread('{}_{}_{}.tif'.format(prefix, row, col))\n",
    "#         ax[row, col].imshow(subimage[650, :, :], cmap='gray', vmin=60, vmax=500)\n",
    "#         ax[row, col].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_scatterplot(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_histogram(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.plot_particles_in_frame(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean1, gSEM1 = hm.plot_individual_msds(prefix, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
