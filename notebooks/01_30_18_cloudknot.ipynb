{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import diff_classifier.imagej as ij\n",
    "import boto3\n",
    "import os.path as op\n",
    "import diff_classifier.aws as aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck\n",
    "import diff_classifier.knotlets as kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_track(filename):\n",
    "    \n",
    "    import diff_classifier.imagej as ij\n",
    "    import diff_classifier.utils as ut\n",
    "    import diff_classifier.aws as aws\n",
    "    import os.path as op\n",
    "    import pandas as pd\n",
    "    \n",
    "    aws.download_s3(filename, op.split(filename)[1])\n",
    "    \n",
    "    outfile = 'Traj_' + op.split(filename)[1].split('.')[0] + '.csv'\n",
    "    local_im = op.join(os.getcwd(), op.split(filename)[1])\n",
    "    if not op.isfile(outfile):\n",
    "        ij.track(local_im, outfile, template=None, fiji_bin=None, radius=4.5, threshold=0., \n",
    "              do_median_filtering=True, quality=4.5, median_intensity=300.0, snr=0.0, \n",
    "              linking_max_distance=7.0, gap_closing_max_distance=10.0, max_frame_gap=2,\n",
    "              track_displacement=10.0)\n",
    "\n",
    "        aws.upload_s3(outfile, op.join(op.split(filename)[0], outfile))\n",
    "    print(\"Done with tracking.  Should output file of name {}\".format(op.join(op.split(filename)[0], outfile)))\n",
    "    \n",
    "    #return ut.csv_to_pd(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track = []\n",
    "for i in range(0, 4):\n",
    "    for j in range(0, 4):\n",
    "        to_track.append('01_18_Experiment/P1/P1_S1_L_0001_{}_{}.tif'.format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_installs=('https://github.com/ccurtis7/diff_classifier.git@scaleup')\n",
    "my_image = ck.DockerImage(func=download_and_track, base_image='arokem/python3-fiji:0.3', github_installs=github_installs)\n",
    "\n",
    "#Step here: delete user info from newly created docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_file = open(my_image.docker_path)\n",
    "docker_string = docker_file.read()\n",
    "docker_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1 = docker_string.find('# Create a default user')\n",
    "cut2 = docker_string[cut1:].find('\\n\\n') + cut1\n",
    "new_docker = docker_string[0:cut1]+docker_string[cut2:]\n",
    "docker_overwrite = open(my_image.docker_path, 'w')\n",
    "docker_overwrite.write(new_docker)\n",
    "docker_overwrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cloudknot.cloudknot:You specified configuration arguments for a knot that already exists. Cloudknot has returned the pre-existing knot, ignoring all of your other input parameters, which may or may not be the same. You should proceed with caution and confirm that this knot's parameters are as expected. If you want to be extra-safe, choose a different name or clobber this pre-existing knot and instantiate a new one with your input arguments.\n"
     ]
    },
    {
     "ename": "ResourceDoesNotExistException",
     "evalue": "jobId c0438220-521a-4d31-944b-5d9cf66a1671 does not exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceDoesNotExistException\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7980fcf4af9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m knot = ck.Knot(name='download_and_track_with_my_image_5',\n\u001b[1;32m      2\u001b[0m                \u001b[0mdocker_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                pars_policies=('AmazonS3FullAccess',))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/cloudknot-0.3.dev0-py2.7.egg/cloudknot/cloudknot.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, pars, pars_policies, docker_image, func, image_script_path, image_work_dir, image_github_installs, username, repo_name, image_tags, job_definition_name, job_def_vcpus, memory, retries, compute_environment_name, instance_types, resource_type, min_vcpus, max_vcpus, desired_vcpus, image_id, ec2_key_pair, ce_tags, bid_percentage, job_queue_name, priority)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_knot_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'job_ids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0mjob_definition_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_definition_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob_definition_name\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/cloudknot-0.3.dev0-py2.7.egg/cloudknot/aws/batch.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, job_id, name, job_queue, job_definition, input, starmap, environment_variables)\u001b[0m\n\u001b[1;32m   1513\u001b[0m                 raise ResourceDoesNotExistException(\n\u001b[1;32m   1514\u001b[0m                     \u001b[0;34m'jobId {id:s} does not exists'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m                     \u001b[0mjob_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m                 )\n\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceDoesNotExistException\u001b[0m: jobId c0438220-521a-4d31-944b-5d9cf66a1671 does not exists"
     ]
    }
   ],
   "source": [
    "knot = ck.Knot(name='download_and_track_with_my_image_5',\n",
    "               docker_image = my_image,\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = results[0]\n",
    "r0.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_split(filename):\n",
    "    \n",
    "    import diff_classifier.imagej as ij\n",
    "    import diff_classifier.aws as aws\n",
    "    import os.path as op\n",
    "    \n",
    "    local_name = op.split(filename)[1]\n",
    "    DIR = op.split(filename)[0]\n",
    "    try1 = filename.split('.')[0] + '_0_0.tif'\n",
    "    try2 = filename.split('.')[0] + '_3_3.tif'\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        obj = s3.head_object(Bucket='ccurtis7.pup', Key=try1)\n",
    "    except:\n",
    "        try:\n",
    "            obj = s3.head_object(Bucket='ccurtis7.pup', Key=try2)\n",
    "        except:\n",
    "            aws.download_s3(filename, local_name)\n",
    "            names = ij.partition_im(local_name)\n",
    "            for name in names:\n",
    "                aws.upload_s3(name, op.join(op.split(filename)[0], name))\n",
    "    print(\"Done with splitting.  Should output file of name {}\".format(op.join(op.split(filename)[0], name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pups = [\"P1\", \"P2\", \"P3\"]\n",
    "slices = [\"S1\", \"S2\", \"S3\"]\n",
    "hemis = [\"R\", \"L\"]\n",
    "videos = 15\n",
    "folder = '01_18_Experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for i in range(10, 15):\n",
    "    missing.append(\"P1_S2_R_00{}.tif\".format(i))\n",
    "\n",
    "for i in range(10, 15):\n",
    "    missing.append(\"P2_S3_L_00{}.tif\".format(i))\n",
    "    \n",
    "for i in range(0, 15):\n",
    "    missing.append(\"P3_S3_L_{}.tif\".format(\"%04d\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_partition = []\n",
    "for pup in pups:\n",
    "    for slic in slices:\n",
    "        for hemi in hemis:\n",
    "            for i in range(0, videos):\n",
    "                name = \"{}/{}/{}_{}_{}_{}.tif\".format(folder, pup, pup, slic, hemi, \"%04d\" % i)\n",
    "                if not name in missing:\n",
    "                    to_partition.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in to_partition:\n",
    "    download_and_split(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm P1_S1_R_0000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3.Object(\"ccurtis7.pup\", '01_18_Experiment/test_file.tif').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "result = s3.list_objects_v2(Bucket=\"ccurtis7.pup\", Prefix=\"/01_18_Experiment/test_filebook.tif\")\n",
    "\n",
    "exists = False\n",
    "if result:\n",
    "    exists = True\n",
    "\n",
    "print(exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in result.get('Contents', []):\n",
    "    if obj['Key'] == \"/01_18_Experiment/test_filebook.tif\":\n",
    "        print('Object here')\n",
    "    else:\n",
    "        print('Object not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    obj = s3.head_object(Bucket='ccurtis7.pup', Key=\"01_18_Experiment/test_file.tif\")\n",
    "except:\n",
    "    print(\"Does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
